{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# import tensorflow_addons as tfa\n",
    "import keras\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import string\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors as word2vec\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_text_path = '../data/target_vecs.txt'\n",
    "all_funcs_data_path = '../data/bcb_funcs_all.tsv'\n",
    "pairs_id_path = '../data/bcb_pair_ids.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dim = 384\n",
    "max_sequence_length = 32\n",
    "output_dim = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_funcs = pd.read_csv(all_funcs_data_path, delimiter=\"\\t\",header=None)\n",
    "with open(pairs_id_path, 'rb') as f:\n",
    "    pair_ids = pickle.load(f).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(pair_ids, test_size=0.2, random_state=42, stratify=pair_ids[:,2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "code2vec = word2vec.load_word2vec_format(vectors_text_path, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproces(s):\n",
    "    s = s.lower()\n",
    "    s = s.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "    s = s.split(\" \")\n",
    "    final = [0 for _ in range(max_sequence_length)]\n",
    "    counter = 0\n",
    "    for word in s:\n",
    "        word = word.strip()\n",
    "        if len(word) > 0 and word in code2vec:\n",
    "            final[counter] = code2vec.vocab[word].index\n",
    "            counter += 1\n",
    "        \n",
    "        if counter >= max_sequence_length:\n",
    "            break\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = dict()\n",
    "for index, row in all_funcs.iterrows():\n",
    "    processed_function = preproces(row[1])\n",
    "    functions[int(row[0])] = processed_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keras_dataset(data):\n",
    "    x = [[],[]]\n",
    "    y = []\n",
    "    for id1,id2,label in data:\n",
    "        try:\n",
    "            x[0].append(functions[id1])\n",
    "            x[1].append(functions[id2])\n",
    "            y.append(label)\n",
    "        except KeyError:\n",
    "            continue\n",
    "    x = np.array(x)\n",
    "    print(x.shape)\n",
    "    x = [x[0,:],x[1,:]]\n",
    "\n",
    "    y = to_categorical(y)\n",
    "    print(y.shape)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 78013, 32)\n",
      "(78013, 6)\n",
      "(2, 19502, 32)\n",
      "(19502, 6)\n"
     ]
    }
   ],
   "source": [
    "x,y  = get_keras_dataset(train_data)\n",
    "test_x, test_y = get_keras_dataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = code2vec.get_keras_embedding(train_embeddings=False)\n",
    "\n",
    "\n",
    "lstm_layer = LSTM(embeddings_dim, dropout=0.3, recurrent_dropout=0.3)\n",
    "\n",
    "in_1 = Input(shape=(max_sequence_length,), dtype='int32')\n",
    "emb_1 = embedding_layer(in_1)\n",
    "lstm_1 = lstm_layer(emb_1)\n",
    "\n",
    "in_2 = Input(shape=(max_sequence_length,), dtype='int32')\n",
    "emb_2 = embedding_layer(in_2)\n",
    "lstm_2 = lstm_layer(emb_2)\n",
    "\n",
    "\n",
    "merged = concatenate([lstm_1, lstm_2])\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dropout(0.3)(merged)\n",
    "merged = Dense(512, activation='relu')(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dropout(0.3)(merged)\n",
    "preds = Dense(output_dim, activation='softmax')(merged)\n",
    "\n",
    "model = Model(inputs=[in_1, in_2], outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', \n",
    "              metrics=['acc',tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 32, 384)      117451392   input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 384)          1181184     embedding_2[0][0]                \n",
      "                                                                 embedding_2[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 768)          0           lstm_2[0][0]                     \n",
      "                                                                 lstm_2[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 768)          3072        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 768)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          393728      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 512)          2048        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 512)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 6)            3078        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 119,034,502\n",
      "Trainable params: 1,580,550\n",
      "Non-trainable params: 117,453,952\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 62410 samples, validate on 15603 samples\n",
      "Epoch 21/25\n",
      "62410/62410 [==============================] - 114s 2ms/step - loss: 0.3467 - acc: 0.8799 - recall_4: 0.8222 - precision_4: 0.8493 - val_loss: 0.4405 - val_acc: 0.8644 - val_recall_4: 0.8232 - val_precision_4: 0.8500\n",
      "Epoch 22/25\n",
      "62410/62410 [==============================] - 124s 2ms/step - loss: 0.3438 - acc: 0.8808 - recall_4: 0.8244 - precision_4: 0.8508 - val_loss: 0.4443 - val_acc: 0.8650 - val_recall_4: 0.8254 - val_precision_4: 0.8516\n",
      "Epoch 23/25\n",
      "62410/62410 [==============================] - 123s 2ms/step - loss: 0.3336 - acc: 0.8836 - recall_4: 0.8265 - precision_4: 0.8524 - val_loss: 0.4459 - val_acc: 0.8654 - val_recall_4: 0.8275 - val_precision_4: 0.8531\n",
      "Epoch 24/25\n",
      "62410/62410 [==============================] - 123s 2ms/step - loss: 0.3287 - acc: 0.8850 - recall_4: 0.8285 - precision_4: 0.8539 - val_loss: 0.4545 - val_acc: 0.8648 - val_recall_4: 0.8294 - val_precision_4: 0.8545\n",
      "Epoch 25/25\n",
      "62410/62410 [==============================] - 123s 2ms/step - loss: 0.3223 - acc: 0.8873 - recall_4: 0.8304 - precision_4: 0.8553 - val_loss: 0.4563 - val_acc: 0.8635 - val_recall_4: 0.8313 - val_precision_4: 0.8559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f575c2e4630>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,\n",
    "          y,\n",
    "          initial_epoch=20,\n",
    "          epochs=25,\n",
    "          validation_split=0.2,\n",
    "          batch_size=64,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19502/19502 [==============================] - 10s 497us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4632954556182059, 0.8619115948677063, 0.831502377986908, 0.8560125827789307]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
