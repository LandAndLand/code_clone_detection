{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import GraphConv, TopKPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "\n",
    "from code_parser import *\n",
    "from dataset import CloneDataset\n",
    "\n",
    "SEED = 2334\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "class NetBasic(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, hparams):\n",
    "        super(NetBasic, self).__init__()\n",
    "\n",
    "        self.hparams = hparams\n",
    "\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        self.conv1 = GraphConv(self.hparams.num_features, 128)\n",
    "        self.pool1 = TopKPooling(128, ratio=0.8)\n",
    "        self.conv2 = GraphConv(128, 128)\n",
    "        self.pool2 = TopKPooling(128, ratio=0.8)\n",
    "        self.conv3 = GraphConv(128, 128)\n",
    "        self.pool3 = TopKPooling(128, ratio=0.8)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(256, 128)\n",
    "        self.lin2 = torch.nn.Linear(128, 64)\n",
    "        self.lin3 = torch.nn.Linear(64, self.hparams.num_classes)\n",
    "\n",
    "    def forward_(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool3(x, edge_index, None, batch)\n",
    "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 + x2 + x3\n",
    "\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = F.log_softmax(self.lin3(x), dim=-1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, data):\n",
    "        return self.forward_(data)\n",
    "\n",
    "    def training_step(self, data, batch_idx):\n",
    "       \n",
    "        output = self.forward(data)\n",
    "        loss = F.nll_loss(output, data.y)\n",
    "\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, data, batch_idx):\n",
    "\n",
    "        output = self.forward(data)\n",
    "        loss = F.nll_loss(output, data.y)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        acc = pred.eq(data.y).type(torch.float32).mean()\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "\n",
    "        tensorboard_logs = {'avg_val_loss': avg_loss, 'avg_val_acc': avg_acc}\n",
    "        return {'val_loss': avg_loss, 'val_acc': avg_acc, 'log': tensorboard_logs}\n",
    "\n",
    "    def test_step(self, data, batch_idx):\n",
    "        output = self.forward(data)\n",
    "        loss = F.nll_loss(output, data.y)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        acc = pred.eq(data.y).type(torch.float32).mean()\n",
    "        return {'test_loss': loss, 'test_acc': acc}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['test_acc'] for x in outputs]).mean()\n",
    "\n",
    "        tensorboard_logs = {'avg_test_loss': avg_loss, 'avg_test_acc': avg_acc}\n",
    "        return {'test_loss': avg_loss, 'test_acc': avg_acc, 'log': tensorboard_logs}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def prepare_data(self):\n",
    "        dataset = CloneDataset(root=self.hparams.root,\n",
    "                               functions_path=os.path.join(self.hparams.root, \"functions\"),\n",
    "                               pairs_path=os.path.join(self.hparams.root, \"bcb_pair_ids.pkl\"),\n",
    "                               transform=T.NormalizeFeatures())\n",
    "\n",
    "        dataset = dataset.shuffle()\n",
    "        n = (len(dataset) + 9) // 10\n",
    "        self.test_dataset = dataset[:n]\n",
    "        self.val_dataset = dataset[n:2 * n]\n",
    "        self.train_dataset = dataset[2 * n:]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # REQUIRED\n",
    "        return DataLoader(self.train_dataset,\n",
    "                          batch_size=self.hparams.batch_size,\n",
    "                          num_workers=self.hparams.workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          batch_size=self.hparams.batch_size,\n",
    "                          num_workers=self.hparams.workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(self.test_dataset,\n",
    "                          batch_size=self.hparams.batch_size,\n",
    "                          num_workers=self.hparams.workers)\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        \"\"\"\n",
    "        Specify the hyperparams for this LightningModule\n",
    "        \"\"\"\n",
    "        # MODEL specific\n",
    "        parser = ArgumentParser(parents=[parent_parser], add_help=False)\n",
    "\n",
    "        parser.add_argument('--learning_rate', default=0.0001, type=float)\n",
    "        parser.add_argument('--batch_size', default=32, type=int)\n",
    "        parser.add_argument('--workers', default='8', type=int)\n",
    "        parser.add_argument('--num_classes', default='6', type=int)\n",
    "        parser.add_argument('--num_features', default='384', type=int)\n",
    "\n",
    "        parser.add_argument('--root', type=str, required=True)\n",
    "\n",
    "        # training specific (for this model)\n",
    "        parser.add_argument('--gpus', type=int, default=1, help='how many gpus')\n",
    "\n",
    "        return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    learning_rate=0.0001,\n",
    "    batch_size=8,\n",
    "    workers=4,\n",
    "    num_classes=6,\n",
    "    num_features=384,\n",
    "    gpu=1,\n",
    "    root=\"../data/\",\n",
    "    max_nb_epochs=2\n",
    ")\n",
    "from argparse import Namespace\n",
    "hparams = Namespace(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NetBasic(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "\n",
      "   | Name      | Type        | Params\n",
      "--------------------------------------\n",
      "0  | conv1     | GraphConv   | 98 K  \n",
      "1  | conv1.lin | Linear      | 49 K  \n",
      "2  | pool1     | TopKPooling | 128   \n",
      "3  | conv2     | GraphConv   | 32 K  \n",
      "4  | conv2.lin | Linear      | 16 K  \n",
      "5  | pool2     | TopKPooling | 128   \n",
      "6  | conv3     | GraphConv   | 32 K  \n",
      "7  | conv3.lin | Linear      | 16 K  \n",
      "8  | pool3     | TopKPooling | 128   \n",
      "9  | lin1      | Linear      | 32 K  \n",
      "10 | lin2      | Linear      | 8 K   \n",
      "11 | lin3      | Linear      | 390   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layoutâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858fd2b8c99e446cb3753e3ae6e56802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), mâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807f9e2ad88a4278ab7aeedfa335cd8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), mâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# most basic trainer, uses good defaults\n",
    "trainer = Trainer(\n",
    "    gpus=0,\n",
    "    max_epochs=200,\n",
    "    distributed_backend=None,\n",
    ")\n",
    "\n",
    "trainer.fit(\n",
    "    model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
