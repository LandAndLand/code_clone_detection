{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import dgl\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from code_parser import *\n",
    "from dgl_dataset import CloneDataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import dgl\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from code_parser import *\n",
    "from dgl_dataset import CloneDataset\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def collate(samples):\n",
    "    # The input `samples` is a list of pairs\n",
    "    #  (graph, label).\n",
    "    graph1, graph2, labels = map(list, zip(*samples))\n",
    "    batched_graph1 = dgl.batch(graph1)\n",
    "    batched_graph2 = dgl.batch(graph2)\n",
    "    return batched_graph1, batched_graph2, torch.tensor(labels)\n",
    "\n",
    "\n",
    "class NetBasic(nn.Module):\n",
    "\n",
    "    def __init__(self, hparams):\n",
    "        super(NetBasic, self).__init__()\n",
    "\n",
    "        self.hparams = hparams\n",
    "\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        self.conv1 = GraphConv(self.hparams.num_features, self.hparams.hidden_dim)\n",
    "        self.conv2 = GraphConv(self.hparams.hidden_dim, self.hparams.hidden_dim)\n",
    "#         self.conv3 = GraphConv(self.hparams.hidden_dim, self.hparams.hidden_dim)\n",
    "        self.classify = nn.Linear(self.hparams.hidden_dim * 2, self.hparams.num_classes)\n",
    "\n",
    "    def forward_(self, g1, g2):\n",
    "        h1 = g1.ndata['data'].view(-1, self.hparams.num_features).float().to(device)\n",
    "        h1 = F.relu(self.conv1(g1, h1))\n",
    "        h1 = F.relu(self.conv2(g1, h1))\n",
    "#         h1 = F.relu(self.conv3(g1, h1))\n",
    "        g1.ndata['h'] = h1\n",
    "\n",
    "        h2 = g2.ndata['data'].view(-1, self.hparams.num_features).float().to(device)\n",
    "        h2 = F.relu(self.conv1(g2, h2))\n",
    "        h2 = F.relu(self.conv2(g2, h2))\n",
    "#         h2 = F.relu(self.conv3(g2, h2))\n",
    "        g2.ndata['h'] = h2\n",
    "\n",
    "        hg1 = dgl.mean_nodes(g1, 'h')\n",
    "        hg2 = dgl.mean_nodes(g2, 'h')\n",
    "\n",
    "        return F.log_softmax(self.classify(torch.cat([hg1, hg2], dim=-1)), dim=-1)\n",
    "\n",
    "    def forward(self, g1, g2):\n",
    "        return self.forward_(g1, g2)\n",
    "\n",
    "    def training_step(self, data):\n",
    "        g1, g2, label = data\n",
    "        output = self.forward(g1, g2)\n",
    "        loss = F.nll_loss(output, label.to(device))\n",
    "        del output\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def validation_step(self, data):\n",
    "        g1, g2, label = data\n",
    "        output = self.forward(g1, g2)\n",
    "        loss = F.nll_loss(output, label.to(device))\n",
    "        pred = output.max(dim=1)[1]\n",
    "        acc = pred.eq(label.cuda()).type(torch.float32).mean()\n",
    "        ret = {'val_loss': loss.item(), 'val_acc': acc.item()}\n",
    "        del loss\n",
    "        del pred\n",
    "        del output\n",
    "        del acc\n",
    "        return ret\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = np.mean([x['val_loss'] for x in outputs])\n",
    "        avg_acc = np.mean([x['val_acc'] for x in outputs])\n",
    "\n",
    "        return {'val_loss': avg_loss, 'val_acc': avg_acc}\n",
    "\n",
    "#         def test_step(self, data, batch_idx):\n",
    "#             g1, g2, label = data\n",
    "#             output = self.forward(g1, g2)\n",
    "#             loss = F.cross_entropy(output, label)\n",
    "#             pred = torch.softmax(output, 1).max(dim=1)[1]\n",
    "#             acc = pred.eq(data.y).type(torch.float32).mean()\n",
    "#             return {'test_loss': loss, 'test_acc': acc}\n",
    "\n",
    "#         def test_epoch_end(self, outputs):\n",
    "#             avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "#             avg_acc = torch.stack([x['test_acc'] for x in outputs]).mean()\n",
    "\n",
    "#             tensorboard_logs = {'avg_test_loss': avg_loss, 'avg_test_acc': avg_acc}\n",
    "#             return {'test_loss': avg_loss, 'test_acc': avg_acc, 'log': tensorboard_logs}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "#         scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "        return optimizer\n",
    "\n",
    "    def prepare_data(self):\n",
    "        dataset = CloneDataset(\n",
    "            functions_path=os.path.join(self.hparams.root, \"dgl_functions\"),\n",
    "            pairs_path=os.path.join(self.hparams.root, \"bcb_pair_ids.pkl\"),\n",
    "        )\n",
    "\n",
    "        n = len(dataset)\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = dgl.data.utils.split_dataset(dataset, frac_list =[0.6, 0.15, 0.25], shuffle=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # REQUIRED.\n",
    "        return DataLoader(self.train_dataset,\n",
    "                          batch_size=self.hparams.batch_size,\n",
    "                          num_workers=self.hparams.workers,\n",
    "                          shuffle=True,\n",
    "                          collate_fn=collate)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          shuffle=True,\n",
    "                          batch_size=self.hparams.batch_size,\n",
    "                          num_workers=self.hparams.workers,\n",
    "                          collate_fn=collate)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(self.test_dataset,\n",
    "                              batch_size=self.hparams.batch_size,\n",
    "                              num_workers=self.hparams.workers,\n",
    "                              collate_fn=collate)\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args():\n",
    "        parser = ArgumentParser(add_help=False)\n",
    "\n",
    "        parser.add_argument('--learning_rate', default=0.0001, type=float)\n",
    "        parser.add_argument('--batch_size', default=32, type=int)\n",
    "        parser.add_argument('--workers', default='8', type=int)\n",
    "        parser.add_argument('--num_classes', default='6', type=int)\n",
    "        parser.add_argument('--num_features', default='384', type=int)\n",
    "        parser.add_argument('--hidden_dim', default='284', type=int)\n",
    "\n",
    "        parser.add_argument('--root', type=str, required=True)\n",
    "\n",
    "        # training specific (for this model)\n",
    "        parser.add_argument('--gpus', type=int, default=1, help='how many gpus')\n",
    "\n",
    "        return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    learning_rate=0.0001,\n",
    "    batch_size=64,\n",
    "    workers=16,\n",
    "    num_classes=6,\n",
    "    num_features=384,\n",
    "    hidden_dim=284,\n",
    "    gpu=1,\n",
    "    root=\"../data/\",\n",
    "    max_nb_epochs=2\n",
    ")\n",
    "from argparse import Namespace\n",
    "\n",
    "hparams = Namespace(**params)\n",
    "model = NetBasic(hparams).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.prepare_data()\n",
    "train_loader = model.train_dataloader()\n",
    "val_loader = model.val_dataloader()\n",
    "\n",
    "optimizer = model.configure_optimizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1; loss: 1.5718147082406966; val_loss: 1.5021113094804588; val_acc: 0.39115289595449854\n",
      "Epoch: 2; loss: 1.4472227393603716; val_loss: 1.4085114486352845; val_acc: 0.44939022644638493\n",
      "Epoch: 3; loss: 1.376513532080937; val_loss: 1.363259007837054; val_acc: 0.4504603826843495\n",
      "Epoch: 4; loss: 1.3500609616764256; val_loss: 1.345457940122446; val_acc: 0.46298982990360676\n",
      "Epoch: 5; loss: 1.3365954809501523; val_loss: 1.3373464132500528; val_acc: 0.45173523324545817\n",
      "Epoch: 6; loss: 1.3283379014072523; val_loss: 1.3372333023745941; val_acc: 0.4819904906780959\n",
      "Epoch: 7; loss: 1.323644720465759; val_loss: 1.32399758345175; val_acc: 0.47689108830352017\n",
      "Epoch: 8; loss: 1.3181055261789123; val_loss: 1.3268334084723195; val_acc: 0.4696549644376513\n",
      "Epoch: 9; loss: 1.3154714620178514; val_loss: 1.3189888312827032; val_acc: 0.4795305676855895\n",
      "Epoch: 10; loss: 1.3129876966033478; val_loss: 1.3170895571271406; val_acc: 0.4990411687105504\n",
      "Epoch: 11; loss: 1.3113568480548963; val_loss: 1.3152031226970222; val_acc: 0.47013617563976473\n",
      "Epoch: 12; loss: 1.3093037406603496; val_loss: 1.3129369387460068; val_acc: 0.4765678866721657\n",
      "Epoch: 13; loss: 1.3079189166996648; val_loss: 1.3132598800950697; val_acc: 0.47925764192139736\n",
      "Epoch: 14; loss: 1.3064988546032723; val_loss: 1.3124811128757927; val_acc: 0.4976585843157039\n",
      "Epoch: 15; loss: 1.3045978271244654; val_loss: 1.308086490006426; val_acc: 0.47680490115844526\n",
      "Epoch: 16; loss: 1.3030597375390307; val_loss: 1.3056448016104218; val_acc: 0.5025927947598253\n",
      "Epoch: 18; loss: 1.2999780929153735; val_loss: 1.3059050448596738; val_acc: 0.5100838888160006\n",
      "Epoch: 19; loss: 1.2983913781864396; val_loss: 1.301867308574993; val_acc: 0.49072052401746724\n",
      "Epoch: 20; loss: 1.295626355520363; val_loss: 1.2983871864960184; val_acc: 0.49634063998684613\n",
      "Epoch: 21; loss: 1.293666389991677; val_loss: 1.3001659660880742; val_acc: 0.5147810847738424\n",
      "Epoch: 22; loss: 1.2915150129078516; val_loss: 1.2995862034210472; val_acc: 0.4846730635676321\n",
      "Epoch: 23; loss: 1.2888312153477486; val_loss: 1.2925449750308906; val_acc: 0.4980248793243841\n",
      "Epoch: 24; loss: 1.2867506011587675; val_loss: 1.288913251531176; val_acc: 0.5038676454510751\n",
      "loss = 1.2932539782505261\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30; loss: 1.268608954174271; val_loss: 1.2709775689387426; val_acc: 0.5347298034934498\n",
      "Epoch: 31; loss: 1.265187202190441; val_loss: 1.2692643167150073; val_acc: 0.5369168007217641\n",
      "Epoch: 32; loss: 1.2621484750606975; val_loss: 1.269699484500302; val_acc: 0.5109170305676856\n",
      "Epoch: 33; loss: 1.2596573156085822; val_loss: 1.2650365316711658; val_acc: 0.5104178637916865\n",
      "Epoch: 34; loss: 1.2561735666514746; val_loss: 1.25993197609764; val_acc: 0.5386118134036335\n",
      "Epoch: 35; loss: 1.2537280668326414; val_loss: 1.2618516311374814; val_acc: 0.5335698689956332\n",
      "Epoch: 36; loss: 1.251211466033602; val_loss: 1.2580530690313947; val_acc: 0.5326146288209607\n",
      "Epoch: 37; loss: 1.2489989671550814; val_loss: 1.2571510498180138; val_acc: 0.5302444840883064\n",
      "loss = 1.2465003420199667\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43; loss: 1.2364188019695177; val_loss: 1.250118097363601; val_acc: 0.5243334865205673\n",
      "Epoch: 44; loss: 1.2345497346966645; val_loss: 1.2398302693033842; val_acc: 0.5292353770618355\n",
      "Epoch: 45; loss: 1.233475890511372; val_loss: 1.2384285333375222; val_acc: 0.5447634164422881\n",
      "Epoch: 46; loss: 1.2311906606121792; val_loss: 1.2439895277460589; val_acc: 0.5460598138222007\n",
      "Epoch: 47; loss: 1.22978384514324; val_loss: 1.241427165972614; val_acc: 0.5258812629760092\n",
      "Epoch: 48; loss: 1.2282388257198646; val_loss: 1.2357021898161376; val_acc: 0.5560431509038767\n",
      "Epoch: 49; loss: 1.2269356030584033; val_loss: 1.2351091027780392; val_acc: 0.5473490289725591\n",
      "Epoch: 50; loss: 1.2248926827816364; val_loss: 1.2315349206653745; val_acc: 0.5559964664117738\n",
      "Epoch: 51; loss: 1.223686889025683; val_loss: 1.2376016349771657; val_acc: 0.5267718626942697\n",
      "Epoch: 52; loss: 1.2221573748875185; val_loss: 1.2263885614132777; val_acc: 0.5506097736837562\n",
      "Epoch: 53; loss: 1.2203353123586687; val_loss: 1.231842850493552; val_acc: 0.5308154734201306\n",
      "Epoch: 54; loss: 1.2188764985141858; val_loss: 1.2281331982154513; val_acc: 0.5304994541484717\n",
      "loss = 1.2204424929062216\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61; loss: 1.209156148420657; val_loss: 1.214129301918646; val_acc: 0.5498376808832827\n",
      "Epoch: 62; loss: 1.207327799523463; val_loss: 1.2115755843803873; val_acc: 0.5577273902414147\n",
      "Epoch: 63; loss: 1.205938515897657; val_loss: 1.212170484544929; val_acc: 0.562589778259852\n",
      "Epoch: 64; loss: 1.2040549038537864; val_loss: 1.2115608063327172; val_acc: 0.5439015455121036\n",
      "Epoch: 65; loss: 1.2039036597059072; val_loss: 1.2155132270275766; val_acc: 0.5276337336244541\n",
      "Epoch: 66; loss: 1.2017301977006465; val_loss: 1.2095299282448781; val_acc: 0.53286600789649\n",
      "Epoch: 67; loss: 1.1997190470252532; val_loss: 1.2040460994670485; val_acc: 0.5599790277959998\n",
      "Epoch: 68; loss: 1.1987790369596638; val_loss: 1.2045811620341638; val_acc: 0.5481713973799127\n",
      "Epoch: 69; loss: 1.1975358133759004; val_loss: 1.2023113973796629; val_acc: 0.5633941909631788\n",
      "loss = 1.1965983022343032\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76; loss: 1.1890501338276056; val_loss: 1.2002802584889674; val_acc: 0.5378756320112137\n",
      "Epoch: 77; loss: 1.1880046372856599; val_loss: 1.1955050214409308; val_acc: 0.548447914258882\n",
      "Epoch: 78; loss: 1.1869984207257547; val_loss: 1.1928295297914198; val_acc: 0.5572964549064636\n",
      "Epoch: 79; loss: 1.1858535543165571; val_loss: 1.199061290145441; val_acc: 0.5245453632034068\n",
      "Epoch: 80; loss: 1.1846199941113997; val_loss: 1.1903158460121488; val_acc: 0.5569983910785492\n",
      "loss = 1.1835739525289484\r"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 201):\n",
    "    \n",
    "    model.train()\n",
    "    losses = []\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        logs = model.training_step(data)\n",
    "        loss = logs['loss']\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        print(f\"loss = {np.mean(losses)}\", end=\"\\r\")\n",
    "        del loss\n",
    "    \n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    for data in val_loader:\n",
    "        with torch.no_grad():\n",
    "            log = model.validation_step(data)\n",
    "            outputs.append(log)\n",
    "    logs = model.validation_epoch_end(outputs)\n",
    "    del outputs\n",
    "    \n",
    "    print(f\"Epoch: {epoch}; loss: {np.mean(losses)}; val_loss: {logs['val_loss']}; val_acc: {logs['val_acc']}\")\n",
    "\n",
    "    torch.save(model.state_dict(), \"../data/dgl_play.pt\")\n",
    "    \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f3547744b442>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "outputs = []\n",
    "for data in test_loader:\n",
    "    with torch.no_grad():\n",
    "        log = model.validation_step(data)\n",
    "        outputs.append(log)\n",
    "logs = model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
