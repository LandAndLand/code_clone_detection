{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import string\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors as word2vec\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_text_path = 'data/target_vecs.txt'\n",
    "all_funcs_data_path = 'data/bcb_funcs_all.tsv'\n",
    "pairs_id_path = 'data/bcb_pair_ids.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dim = 384\n",
    "max_sequence_length = 32\n",
    "output_dim = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_funcs = pd.read_csv(all_funcs_data_path, delimiter=\"\\t\",header=None)\n",
    "with open(pairs_id_path, 'rb') as f:\n",
    "    pair_ids = pickle.load(f).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(pair_ids, test_size=0.2, random_state=42, stratify=pair_ids[:,2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "code2vec = word2vec.load_word2vec_format(vectors_text_path, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproces(s):\n",
    "    s = s.lower()\n",
    "    s = s.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "    s = s.split(\" \")\n",
    "    final = [0 for _ in range(max_sequence_length)]\n",
    "    counter = 0\n",
    "    for word in s:\n",
    "        word = word.strip()\n",
    "        if len(word) > 0 and word in code2vec:\n",
    "            final[counter] = code2vec.vocab[word].index\n",
    "            counter += 1\n",
    "        \n",
    "        if counter >= max_sequence_length:\n",
    "            break\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = dict()\n",
    "for index, row in all_funcs.iterrows():\n",
    "    processed_function = preproces(row[1])\n",
    "    functions[int(row[0])] = processed_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keras_dataset(data):\n",
    "    x = [[],[]]\n",
    "    y = []\n",
    "    for id1,id2,label in data:\n",
    "        try:\n",
    "            x[0].append(functions[id1])\n",
    "            x[1].append(functions[id2])\n",
    "            y.append(label)\n",
    "        except KeyError:\n",
    "            continue\n",
    "    x = np.array(x)\n",
    "    print(x.shape)\n",
    "    x = [x[0,:],x[1,:]]\n",
    "\n",
    "    y = to_categorical(y)\n",
    "    print(y.shape)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 78013, 32)\n",
      "(78013, 6)\n",
      "(2, 19502, 32)\n",
      "(19502, 6)\n"
     ]
    }
   ],
   "source": [
    "x,y  = get_keras_dataset(train_data)\n",
    "test_x, test_y = get_keras_dataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = code2vec.get_keras_embedding(train_embeddings=False)\n",
    "\n",
    "\n",
    "lstm_layer = LSTM(embeddings_dim, dropout=0.3, recurrent_dropout=0.3)\n",
    "\n",
    "in_1 = Input(shape=(max_sequence_length,), dtype='int32')\n",
    "emb_1 = embedding_layer(in_1)\n",
    "lstm_1 = lstm_layer(emb_1)\n",
    "\n",
    "in_2 = Input(shape=(max_sequence_length,), dtype='int32')\n",
    "emb_2 = embedding_layer(in_2)\n",
    "lstm_2 = lstm_layer(emb_2)\n",
    "\n",
    "\n",
    "merged = concatenate([lstm_1, lstm_2])\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dropout(0.3)(merged)\n",
    "merged = Dense(512, activation='relu')(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dropout(0.3)(merged)\n",
    "preds = Dense(output_dim, activation='softmax')(merged)\n",
    "\n",
    "model = Model(inputs=[in_1, in_2], outputs=preds)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 32)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 32, 384)      117451392   input_6[0][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 384)          1181184     embedding_4[0][0]                \n",
      "                                                                 embedding_4[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 768)          0           lstm_3[0][0]                     \n",
      "                                                                 lstm_3[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 768)          3072        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 768)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 512)          393728      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 512)          2048        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 512)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 6)            3078        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 119,034,502\n",
      "Trainable params: 1,580,550\n",
      "Non-trainable params: 117,453,952\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 62410 samples, validate on 15603 samples\n",
      "Epoch 1/10\n",
      "62410/62410 [==============================] - 114s 2ms/step - loss: 0.9235 - acc: 0.6610 - val_loss: 0.6961 - val_acc: 0.7646\n",
      "Epoch 2/10\n",
      "62410/62410 [==============================] - 109s 2ms/step - loss: 0.6746 - acc: 0.7590 - val_loss: 0.5664 - val_acc: 0.7991\n",
      "Epoch 3/10\n",
      "62410/62410 [==============================] - 108s 2ms/step - loss: 0.6001 - acc: 0.7895 - val_loss: 0.5267 - val_acc: 0.8166\n",
      "Epoch 4/10\n",
      "62410/62410 [==============================] - 117s 2ms/step - loss: 0.5617 - acc: 0.8048 - val_loss: 0.4990 - val_acc: 0.8272\n",
      "Epoch 5/10\n",
      "62410/62410 [==============================] - 118s 2ms/step - loss: 0.5328 - acc: 0.8160 - val_loss: 0.5014 - val_acc: 0.8256\n",
      "Epoch 6/10\n",
      "48128/62410 [======================>.......] - ETA: 25s - loss: 0.5078 - acc: 0.8254"
     ]
    }
   ],
   "source": [
    "model.fit(x,\n",
    "          y,\n",
    "          epochs=10,\n",
    "          validation_split=0.2,\n",
    "          batch_size=64,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
